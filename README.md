# Анализ эффективности обработки тикетов в трекере задач (SQL)

Проект посвящён анализу эффективности обработки тикетов в системе трекинга задач на основе двух таблиц: списка тикетов и справочника резолюций.
Цель — оценить скорость закрытия обращений, структуру исходов (резолюций), выявить закономерности распределения категорий и зафиксировать проблемы качества данных, влияющие на метрики.

## Структура проекта

```
├── sql/
│   ├── 01_init_schema.sql      # Создание таблиц и индексов
│   ├── 02_data_cleaning.sql    # Создание VIEW issues_clean (чистый слой)
│   ├── 03_data_quality.sql     # Проверки качества данных (EDA)
│   └── 04_analysis.sql          # Основные расчёты и метрики
├── docs/
│   ├── analyses_report.md      # Детальный аналитический отчёт
│   └── presentation.pdf        # Презентация результатов
└── README.md                    # Этот файл
```

**Примечание:** SQL-запросы написаны для PostgreSQL и используют специфичные функции (`DATE_TRUNC`, `TO_TIMESTAMP`, `PERCENTILE_CONT`, `FILTER` clause).

## Контекст и цель
Данные описывают жизненный цикл тикета: создание (created), решение (resolved), категория (category) и итог решения (resolution) с привязкой к справочнику резолюций.
В рамках проекта я построил "чистый слой" данных (`issues_clean`) и рассчитал ключевые показатели, которые помогают оценить эффективность поддержки и зоны для улучшения (backlog, справочник резолюций, контроль качества данных).

## Вопросы исследования
- Какова доля тикетов, решённых в тот же месяц, когда они были созданы? 
- Сколько решённых тикетов приходится на каждую резолюцию (по названиям резолюций)? 
- Как распределены категории тикетов и по каким закономерностям/паттернам это распределение сформировано? 
- Какие проблемы качества данных присутствуют и как они могут искажать выводы?

## Данные
### Источники
- `issues.csv` — список тикетов.
- `resolutions.csv` — справочник резолюций.

### Схема (по полям из датасета)
**issues**
- `key` — идентификатор тикета. 
- `created` — время создания в Unix timestamp (миллисекунды).
- `resolved` — время решения в Unix timestamp (миллисекунды), может отсутствовать. 
- `resolution` — идентификатор резолюции (связь с `resolutions.id`).
- `category` — категория тикета (в данных 4 значения: `Local`, `Remote`, `New User`, `Software License`).

**resolutions**
- `id` — идентификатор резолюции (например, `4f6b29cc...`).  
- `key` — название резолюции (например, `fixed`, `won'tFix`, `duplicate` и др.).

### Объём данных
- Таблица `issues`: 51,955 строк. 
- Таблица `resolutions`: 176 строк. 

## Подход к анализу
Анализ выполнен полностью в SQL: первичный EDA → проверка качества → создание "чистого слоя" → расчёт метрик и срезов. 
Для исключения искажений я отфильтровал записи с некорректными датами (epoch) и добавил расчёт времени решения в днях. 

### Чистый слой данных
Создан `VIEW issues_clean`, где:
- `created` и `resolved` конвертируются в дату/время; 
- считается `days_to_resolve`;
- исключаются epoch-анomalies (created < 1000000000000). 

## Ключевые результаты
### 1) Качество данных (то, что влияет на доверие метрикам)
Пропуски:
- Отсутствие даты создания: 3 записи (0.006%). 
- Отсутствие даты решения: 2,766 записей (5.32%). 

Аномалии:
- Тикеты с `created = 1970-01-01` (epoch): 2 записи. 
- Тикеты с обработкой > 1 года: 3 записи. 
- Тикеты, где `resolved < created`: 0 записей. 

Связность со справочником резолюций:
- В `issues` найден 1 тикет с резолюцией, отсутствующей в `resolutions`. 
- В справочнике 176 резолюций, но в данных реально используются только 5 (171 не используются).

### 2) Общая статистика и категории
После очистки:
- Всего тикетов: 51,950. 
- Решённых тикетов: 49,184 (94.67%). 
- Нерешённых тикетов: 2,766 (5.33%). 
- Категорий: 4. 

Распределение категорий:
- `Local`: 26,366 (50.75%).
- `Remote`: 18,167 (34.97%). 
- `New User`: 6,144 (11.83%). 
- `Software License`: 1,273 (2.45%).

**Закономерности распределения категорий:**
- Основной поток обращений формируют `Local` и `Remote` (в сумме 85.72%), что указывает на доминирование технических запросов и необходимость фокусировать ресурсы поддержки на этих типах. 
- `New User` может быть индикатором проблем онбординга/документации (гипотеза для проверки дополнительными данными). 
- `Software License` — редкая и потенциально регламентированная категория (возможен отдельный процесс).
- Категории отличаются по структуре исходов (резолюций): в разных категориях разное распределение типов резолюций, что может указывать на особенности процессов обработки.
- Категории показывают схожую скорость обработки по метрике "решено в тот же месяц" (~95%), но могут различаться по "хвосту" долгих тикетов и структуре backlog.

Подробный анализ закономерностей с конкретными расчётами представлен в разделе 9 файла [`docs/analyses_report.md`](docs/analyses_report.md) и в SQL-запросах файла `sql/04_analysis.sql` (разделы 6, 9). 

### 3) Доля тикетов, решённых в тот же месяц
Среди решённых тикетов (49,184):
- Решено в тот же месяц: **95.48%**. 

Срез по категориям (same-month %):
- `Software License`: ~100%. 
- `Remote`: ~95.35%. 
- `New User`: ~96.29%.
- `Local`: ~95.16%. 

### 4) Резолюции (исходы) — распределение решённых тикетов
Распределение по типам резолюций:
- `Fixed`: 46,808 (95.17%). 
- `Wont Fix`: 1,251 (2.54%). 
- `resolvedByUser`: 791 (1.61%). 
- `Duplicate`: 294 (0.6%). 
- `escalated`: 39 (0.08%). 

Замечание:
- Сильная доминанта `Fixed` может означать как высокую эффективность поддержки, так и укрупнение разных сценариев под одним "исходом" (в идеале это проверяется доп. полями: тип обращения/приоритет/команда/текст тикета).

## Детальный отчёт

Полный аналитический отчёт с интерпретацией результатов, рекомендациями и ограничениями анализа доступен в файле [`docs/analyses_report.md`](docs/analyses_report.md).

## Технические детали

### Используемые технологии
- **SQL** (PostgreSQL) — для всех расчётов и анализа
- **VIEW** — для создания переиспользуемого "чистого слоя" данных
- **Индексы** — для оптимизации JOIN и фильтрации

### Методология
1. **EDA (Exploratory Data Analysis)** — первичное исследование данных
2. **Data Quality Checks** — проверка полноты, аномалий и связности данных
3. **Data Cleaning** — создание очищенного слоя с валидацией
4. **Metrics Calculation** — расчёт ключевых метрик из задания
5. **Pattern Analysis** — выявление закономерностей распределения категорий

