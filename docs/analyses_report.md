# Аналитический отчёт: эффективность обработки тикетов (SQL)

## 1) Контекст и цель
В этом проекте я анализирую работу трекера задач (тикеты службы поддержки/внутреннего сервиса) по историческим данным. Цель анализа — оценить эффективность обработки тикетов, структуру исходов (резолюций), выявить закономерности распределения категорий и сформулировать рекомендации по улучшению процесса и качества данных.

Ключевой принцип: перед расчётом метрик я выполняю проверку качества данных и строю “чистый слой” для аналитики (`issues_clean`), чтобы метрики не искажались аномалиями.

---

## 2) Описание данных
Входные данные состоят из двух таблиц:
- `issues` — список тикетов: `key`, `created`, `resolved`, `resolution`, `category`.
- `resolutions` — справочник резолюций: `id`, `key`.

Особенности:
- Временные поля `created`/`resolved` представлены в формате Unix timestamp в миллисекундах.
- Поле `resolution` в `issues` должно ссылаться на `resolutions.id`.

---

## 3) Проверка качества данных (Data Quality)
Проверка качества данных — обязательный шаг, так как даже небольшое число “битых” записей может сильно влиять на средние значения и доли.

### 3.1 Пропуски
Выявлены пропуски:
- Пропуски в `created` (редко, но критично: без даты создания невозможно считать скорость обработки).
- Пропуски в `resolved` (ожидаемо: это открытые тикеты / backlog).

**Вывод:** метрики скорости решения считаем только по тикетам с заполненным `resolved`, а для анализа backlog выделяем отдельный блок.

### 3.2 Временные аномалии
Проверены аномалии:
- `created` в районе 1970-01-01 (epoch) — некорректные значения.
- `resolved < created` — логическая ошибка (в идеале должна отсутствовать).
- “Долгие” тикеты с временем решения более 365 дней — редкие, но сильно влияющие на среднее.

**Вывод:** epoch-аномалии следует исключать из анализа; “долгие” тикеты анализируются отдельно (как хвост распределения), чтобы понимать природу выбросов.

### 3.3 Связность со справочником резолюций
Проверка referential integrity показала:
- Есть хотя бы один тикет с `resolution`, отсутствующей в `resolutions`.
- Справочник резолюций значительно избыточен: в данных используется малое число резолюций по сравнению с количеством в справочнике.

**Вывод:** справочник нуждается в ревизии; также нужна валидация связности на уровне системы (запрет/алерт на неизвестный `resolution_id`).

---

## 4) Подготовка “чистого слоя” (`issues_clean`)
Создано представление `issues_clean`, где:
- timestamp в мс конвертируется в дату/время (`created_dt`, `resolved_dt`);
- вычисляется длительность обработки в днях `days_to_resolve`;
- исключаются epoch-аномалии по `created`.

**Зачем это нужно:**
- централизованная логика очистки (не размазывать фильтры по всем запросам);
- воспроизводимость анализа;
- корректность метрик.

---

## 5) Базовая описательная статистика
### 5.1 Статус тикетов
Считаются:
- всего тикетов;
- решённые / нерешённые;
- доля решённых.

**Интерпретация:**
- высокая доля решённых тикетов говорит о хорошей пропускной способности процесса;
- наличие нерешённых тикетов формирует backlog, который важно анализировать отдельно (см. раздел 8).

### 5.2 Категории тикетов
Категорий в данных 4. Распределение заметно неравномерное: две категории формируют основную массу тикетов, остальные — существенно меньшую долю.

**Гипотезы (которые можно проверять даже в рамках текущих полей):**
- доминирующие категории отражают “основной поток” обращений;
- редкие категории могут быть регламентированными процессами (например, лицензии) либо признаком отдельной команды/очереди.

---

## 6) Метрика “решено в тот же месяц” (основное требование)
Рассчитана доля тикетов, решённых в тот же месяц, что и месяц создания (по решённым тикетам).

### 6.1 Общий показатель
Метрика показывает высокую долю решений “в пределах месяца”.

**Как интерпретировать корректно:**
- это “грубая” скорость: месяц — достаточно длинный период;
- метрика не показывает хвост (тикеты, решённые за 1–30 дней, смешиваются);
- возможен эффект календаря: тикеты, созданные в конце месяца, могут “проигрывать” по метрике при том же реальном времени решения.

### 6.2 Разрез по категориям
Метрика рассчитана по категориям, различия между ними небольшие.

**Вывод:**
- скорость обработки в целом стабильна между категориями;
- если различия минимальны, то “узкие места” могут лежать не в категории, а в других измерениях (которых нет в данных: приоритет, команда, исполнитель, тип запроса).

---

## 7) Резолюции: структура исходов и скорость обработки
### 7.1 Распределение резолюций
Подсчитано количество решённых тикетов по названиям резолюций.

**Интерпретация:**
- доминирование одной резолюции (например, `fixed`) может означать:
  - действительно высокую долю решаемых инцидентов;
  - либо “схлопывание” разных сценариев под один итоговый статус (если аналитическая дисциплина в заполнении резолюций слабая).
- наличие резолюций типа `duplicate`/`wontFix`/`resolvedByUser` полезно для процессных улучшений:
  - `duplicate` → возможны проблемы с поиском по базе знаний и/или с классификацией;
  - `resolvedByUser` → потенциал самообслуживания (FAQ, подсказки, онбординг);
  - `wontFix` → стоит понять причины (неприоритизировано? невозможно воспроизвести? не в зоне ответственности?).

### 7.2 Время решения по резолюциям
Рассчитаны средние/минимальные/максимальные сроки по резолюциям (с ограничением по выбросам).

**Вывод:**
- сравнение резолюций по времени помогает выявить типы обращений, которые “тянут” сроки;
- важно дополнить среднее квантилями (p50/p90), потому что среднее чувствительно к хвосту.

---

## 8) Backlog: анализ нерешённых тикетов
Нерешённые тикеты — отдельная зона риска, так как:
- они ухудшают пользовательский опыт;
- накапливают “технический долг” поддержки;
- могут свидетельствовать о сбое процесса (например, тикеты без владельца/без SLA).

### 8.1 Возраст открытых тикетов
Рекомендуемая метрика: `days_open = now() - created_dt`.

Что важно смотреть:
- средний возраст backlog по категориям;
- максимальный возраст backlog;
- распределение по “возрастным корзинам” (0–7, 8–30, 31–90, 91–180, 180+).

**Вывод и действие:**
- если есть большая доля “старых” тикетов (90+ дней), нужен процесс triage/cleanup:
  - закрытие неактуальных,
  - эскалация,
  - пересоздание с корректными данными,
  - назначение ответственных.

---

## 9) Закономерности распределения категорий (как “углубить выводы”)
Поскольку в данных мало измерений, “идеальная глубина” достигается не фантазией, а проверяемыми паттернами, доступными из текущих полей.

**Примечание:** Конкретные численные результаты всех расчётов находятся в SQL-запросах файла `sql/04_analysis.sql` (разделы 2, 6, 9). Ниже описан методологический подход к выявлению закономерностей:

Ниже — набор закономерностей, которые можно строго подтвердить SQL:

### 9.1 Категории отличаются по структуре исходов
Проверка: распределение резолюций внутри каждой категории (percent share).

**Что это даёт:**
- если в одной категории выше доля `duplicate`, это может означать проблемы маршрутизации/классификации именно там;
- если в категории выше `resolvedByUser`, это признак потенциала самообслуживания.

### 9.2 Категории отличаются по “хвосту” времени решения
Проверка: p50/p90/p95 `days_to_resolve` по категориям.

**Интерпретация:**
- небольшая разница в среднем может скрывать сильные различия в p90 (пользователь чаще чувствует “плохие” случаи).

### 9.3 Категории отличаются по backlog и его возрасту
Проверка:
- доля нерешённых тикетов по категории;
- aging buckets по категориям.

**Интерпретация:**
- категория может выглядеть “нормально” по решённым тикетам, но создавать непропорционально много долгого backlog.

---

## 10) Рекомендации
### 10.1 Качество данных
- Ввести валидацию timestamp (исключить epoch/нулевые значения).
- Ввести контроль связности `issues.resolution → resolutions.id`.
- Регулярно ревизовать справочник резолюций (удалять/архивировать неиспользуемые, описывать правила применения).

### 10.2 Процесс поддержки
- Внедрить процесс работы с backlog:
  - регулярный triage,
  - правила эскалации,
  - SLA/приоритеты (если есть возможность — добавить поля в данные).
- Для категорий с заметной долей `duplicate`/`resolvedByUser`:
  - улучшить базу знаний,
  - улучшить поиск/подсказки при создании тикета,
  - усилить онбординг для “New User” (если гипотеза подтверждается).

### 10.3 Метрики и мониторинг
- Помимо “same-month rate” использовать SLA-метрики по дням (<=1/3/7/14/30).
- Всегда показывать квантили (p50/p90/p95) и долю тикетов в “хвосте”.

---

## 11) Ограничения анализа
- В данных отсутствуют поля: приоритет, команда/исполнитель, SLA, текст/тема тикета, продукт/сервис.
- Поэтому причины различий можно формулировать как гипотезы, но подтверждать их можно будет только при наличии дополнительных атрибутов.
